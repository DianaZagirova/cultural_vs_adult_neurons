{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35de368a-fd08-41bc-b4ee-de62c648020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from os import listdir\n",
    "import glob\n",
    "import json\n",
    "import seaborn as sns\n",
    "import cooler\n",
    "import bioframe\n",
    "import cooltools\n",
    "from cooltools.lib.numutils import fill_diag\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4050598e-b8b2-48f4-861f-cb0d3778d24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert os.environ['CONDA_DEFAULT_ENV'] == \"cultures_hic\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec6652-48df-434b-a037-3390e51bf1ed",
   "metadata": {},
   "source": [
    "# 1. Get loops positions on Hi-C maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "927f3c56-8cdc-413b-b64f-95ddfb1555df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hg38_arms():\n",
    "    hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "    hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "    hg38_arms = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "    return hg38_arms[hg38_arms.chrom!='chrM'].reset_index(drop=True)\n",
    "    \n",
    "def get_loops(map, loops_name, hg38_arms, path_to_save, maps_directory=path_to_maps, loops_plus_directory=path_to_loops,  binzise = 15_000):\n",
    "    hg38_arms = get_hg38_arms()\n",
    "    loops_plus = pd.read_csv(f'{loops_plus_directory}/{loops_name}', sep='\\t', header=None)\n",
    "    loops_plus.columns = ['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2', 'num', 'kernel']\n",
    "    loops_plus = loops_plus.sort_values(['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2']).reset_index(drop=True)\n",
    "    loops_plus['num'] = [i for i in range(loops_plus.shape[0])]\n",
    "    \n",
    "    loops_plus.to_csv(f\"{loops_plus_directory}/{loops_name.split('bed')[0]}_sorted.bed\", sep='\\t', index=False)\n",
    "    name = map.split(\"/\")[-1].split(\".\")[0]\n",
    "    if \"Heffel\" in map:\n",
    "        name = map.split(\"/\")[-1].split(\".\")[0]\n",
    "    print(name)\n",
    "    clr = cooler.Cooler(f'{map}::/resolutions/{binzise}')\n",
    "    expected = cooltools.expected_cis(clr, view_df=hg38_arms, nproc=16)\n",
    "    plus_hc_loops = []        \n",
    "    stack = cooltools.pileup(clr, \n",
    "                             loops_plus, \n",
    "                             hg38_arms,                                 \n",
    "                             expected_df=expected, \n",
    "                             flank=200000,\n",
    "                             nproc=17)\n",
    "    \n",
    "    stack[:, :, np.all(stack == 0, axis=(0,1))] = np.nan\n",
    "    plus_hc_loops.append(stack)     \n",
    "    np.save(f\"{path_to_save}/{name}_0.13fdr_15000res_small_NaN5_loops.npy\", plus_hc_loops[0]) \n",
    "    assert loops_plus.shape[0] ==  plus_hc_loops[0].shape[0]\n",
    "    return name, plus_hc_loops[0], loops_plus\n",
    "\n",
    "def load_loops_back(maps_plus):\n",
    "    loops = {}\n",
    "    for map in tqdm(maps_plus):        \n",
    "        if \"CTX\" in map:\n",
    "            name = \"Heffel_\"+map.split(\"/\")[-1].split(\".\")[2]\n",
    "        else:\n",
    "            name = map.split(\"/\")[-1].split(\".\")[0]        \n",
    "        plus_hc_loops = np.load(f\"{path_to_save}/{name}_0.13fdr_15000res_small_NaN5_loops.npy\")\n",
    "        loops[name] = plus_hc_loops   \n",
    "    return loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e9a24d0-4837-42d7-9188-565a827206d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 15_000\n",
    "path_to_maps = os.getenv('PATH_TO_MAPS')\n",
    "path_to_loops = \"./loops_data/loops_final_files\"\n",
    "path_to_loops_intensities = \"./loops_data/loops_intensities/\"\n",
    "number_of_files = 23\n",
    "\n",
    "pattern = '0.13fdr_15000res_small_NaN5_final.bed'\n",
    "not_pattern = '.bedped'\n",
    "files = [f for f in listdir(path_to_loops) if pattern in f and not_pattern not in f]\n",
    "files.sort()\n",
    "\n",
    "pattern = 'mcool'\n",
    "maps = [path_to_maps+f for f in listdir(path_to_maps) if pattern in f]\n",
    "maps.sort()\n",
    "assert len(maps) == number_of_files\n",
    "assert len(files) == number_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f5aa2d-3357-417d-bb0a-0141b958eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = list(set([i.split('/')[-1].split(\".\")[0] for i in maps]))\n",
    "maps2loops = {i:k for i,k in zip(maps, files)}\n",
    "with open('./loops_data/maps2loops_mapping.json', 'w') as f:\n",
    "    json.dump(maps2loops, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f82c48f-a405-4c71-b244-02708fbce7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38_arms = get_hg38_arms()\n",
    "loops = {}\n",
    "sorted_loops = {}\n",
    "for map_path, loops_path in maps2loops.items():\n",
    "    name, loops_prep, loops_plus = get_loops(map_path,loops_path, hg38_arms, path_to_loops_intensities)\n",
    "    loops[name] = loops_prep\n",
    "    sorted_loops[name] = loops_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae4b07-5175-454a-a89b-61c6b064ac9f",
   "metadata": {},
   "source": [
    "## 2. Get intensity in 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9851502f-d95e-4459-b7c0-a18f0b4bf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_loops(loops, retain_all_values = False):\n",
    "    first_key = next(iter(loops))  \n",
    "    len_loops = loops[first_key].shape[0]\n",
    "    center = (loops[first_key].shape[1] - 1) // 2 \n",
    "    start_index, end_index = center - 1, center + 2\n",
    "    collect_min = []\n",
    "    loops_values = {map_key: {} for map_key in loops}  \n",
    "\n",
    "    for loop in range(len_loops):\n",
    "        selected_box, min_length, all_values = process_each_loop(loops, loop, start_index, end_index)\n",
    "        collect_min.extend([min_length] * len(loops))  \n",
    "\n",
    "        for i, map_key in enumerate(loops):\n",
    "            \n",
    "            if selected_box[i][:min_length] == []:\n",
    "                appended_value = \"NaN\"\n",
    "            else:\n",
    "                appended_value = np.nanmean(selected_box[i][:min_length])\n",
    "            if retain_all_values:\n",
    "                appended_value = all_values[i]\n",
    "            loops_values[map_key].setdefault(loop, []).append(appended_value)\n",
    "\n",
    "    for map_key in loops:\n",
    "        loops_values[map_key] = [value[0] for value in loops_values[map_key].values()]\n",
    "    return loops_values\n",
    "\n",
    "def process_each_loop(loops, loop, start_index, end_index):\n",
    "    selected_box, all_values = [], []\n",
    "    min_length = 9\n",
    "    for map_key in loops:\n",
    "        array = loops[map_key][loop][start_index:end_index, start_index:end_index]\n",
    "        all_values.append(array)\n",
    "        cleaned_list = array[~np.isnan(array)].tolist()\n",
    "        cleaned_list_temp = [i for i in cleaned_list if i!=0]\n",
    "        if cleaned_list_temp:\n",
    "            cleaned_list = cleaned_list_temp\n",
    "        cleaned_list.sort(reverse=True)\n",
    "        selected_box.append(cleaned_list)\n",
    "        min_length = min(min_length, len(cleaned_list))\n",
    "    return selected_box, min_length, all_values\n",
    "\n",
    "\n",
    "def save_loops(processed_loops_all, data_mean, name_data_all, name_data_mean, path):    \n",
    "    #alll\n",
    "    data_all = processed_loops_all.copy()\n",
    "    for key in data_all:\n",
    "        data_all[key] = [arr.tolist() for arr in data_all[key]]\n",
    "    with open(f'{path}/{name_data_all}.json', 'w') as f:\n",
    "        json.dump(data_all, f)\n",
    "    \n",
    "    ##mean\n",
    "    with open(f'{path}/{name_data_mean}.json', 'w') as f:\n",
    "        json.dump(data_mean, f)\n",
    "\n",
    "def get_3_to_3_loops(loops_intensities, name, binzise = 15_000, path= path_to_loops_intensities):\n",
    "    processed_loops_mean = process_loops(loops_intensities)    \n",
    "    processed_loops_all = process_loops(loops_intensities, retain_all_values=True)\n",
    "    \n",
    "    save_loops(processed_loops_all, processed_loops_mean, f'loops_{name}_0.13fdr_15000res_small_NaN5_3x3bin_all', f'loops_{name}_0.13fdr_15000res_small_NaN5_3x3bin_mean', path)\n",
    "    return processed_loops_mean, processed_loops_all, loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23938db6-0dfb-45f6-a873-ac17dee39604",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_loops_mean_MAPS = {}\n",
    "processed_loops_all_MAPS = {}\n",
    "for name, loops_one in loops.items():\n",
    "    one_loop = {}\n",
    "    one_loop[name] =  loops_one\n",
    "    processed_loops_mean, processed_loops_all, loops = get_3_to_3_loops(one_loop, name)\n",
    "    processed_loops_mean_MAPS.update(processed_loops_mean)\n",
    "    processed_loops_all_MAPS.update(processed_loops_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0838eb-3328-4586-b85d-9d46bc6f88b1",
   "metadata": {},
   "source": [
    "# 3. Merge with intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f82bb271-ae0c-4580-b3b4-bb6a3bb4e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '_mean.json'\n",
    "not_pattern = 'svdv'\n",
    "files_loops_intensities = [f for f in listdir(path_to_loops_intensities) if pattern in f and not_pattern not in f]\n",
    "files_loops_intensities.sort()\n",
    "assert len(files_loops_intensities) == 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24f767c0-1390-4fc8-94d7-d7e997d138d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for name in sorted_loops.keys():    \n",
    "    df = sorted_loops[name]\n",
    "    df[\"intensity_all\"] = processed_loops_all_MAPS[name]\n",
    "    df[\"intensity_mean\"] = processed_loops_mean_MAPS[name]\n",
    "    df.to_csv(f\"{path_to_loops_intensities}/{name}_sampled_dots_final_12000000maxloci_0.13fdr_15000res_small_NaN5_final_sorted_with_intensity.bed\", sep='\\t', index=False)\n",
    "    \n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
